{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text2Dec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8LHD9vlayJn"
      },
      "source": [
        "## 0. Logistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xLDqEM94U1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107b8d0f-5e09-4cf2-ae9f-284a94a7bf54"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3qM2H55CCK3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ff6608-814d-428e-f111-a1f0adeaccbe"
      },
      "source": [
        "!pip install mord\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mord\n",
            "  Downloading https://files.pythonhosted.org/packages/67/9d/c791c841501d9ff4ecb76b57f208dec6cf9f925109c59c995ddec80f9b32/mord-0.6.tar.gz\n",
            "Building wheels for collected packages: mord\n",
            "  Building wheel for mord (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mord: filename=mord-0.6-cp36-none-any.whl size=6009 sha256=d7551860edda74e3c3c8230f9b699a83b036596573e9d5ac31632c72e66d0f66\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/14/b2/244c2cec93a0c6edb29b488bd6b2710ded7e9d457033b86366\n",
            "Successfully built mord\n",
            "Installing collected packages: mord\n",
            "Successfully installed mord-0.6\n",
            "Collecting en_core_web_lg==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
            "\u001b[K     |████████████████████████████████| 827.9MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.4.0)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp36-none-any.whl size=829180944 sha256=bbf6cb775ed53c65d0c57bc0bbeb753f4b041d7cf4d8c5eda2c2464e9dc161a6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z14z9l9l/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajEtSZE_9WaM"
      },
      "source": [
        "import os\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "from mord import LogisticAT\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, accuracy_score, \\\n",
        "                            mean_absolute_error as MAE\n",
        "from sklearn.model_selection import cross_val_score, \\\n",
        "                                    StratifiedShuffleSplit as SSSplit\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import preprocessing as prep\n",
        "from tensorflow.python.keras import models, initializers\n",
        "from tensorflow.python.keras import layers as L                                    \n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6-LlBFSAlQQ"
      },
      "source": [
        "spacy_nlp = spacy.load('en_core_web_lg')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE_RnjpV6bPl"
      },
      "source": [
        "home_path = '/content/drive/My Drive/Colab Notebooks/assgn'\n",
        "data_path = os.path.join(home_path, 'original.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgKbWa9vjlVr"
      },
      "source": [
        "# Texts to Decades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX-Uc0KTxZvz"
      },
      "source": [
        "Task: predict the reviewer’s birth decade (90’s, 80’s, 00’s, etc)  using only text features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf_xTYknBDSv"
      },
      "source": [
        "## 1. Data exploration\n",
        "The dataset was web-scraped around 2016 ([dataset author's post](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews/discussion/65898)). `Atext` concats `Title` and `Review Text`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrszQNH29rjM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "b2bd4a51-2578-4356-b9cc-968cde28e095"
      },
      "source": [
        "df = pd.read_csv(data_path, index_col=0)\n",
        "df.fillna('', inplace=True)\n",
        "df['Atext'] = df['Title'] + ' ' + df['Review Text']\n",
        "## age should be in (6, 106]; shift decades from [1, 9] to [0, 8]\n",
        "df['Dec'] = (2016 - df['Age'] - 1900) // 10 - 1  \n",
        "\n",
        "#### other prediction targets to explore:\n",
        "#### 3-age-group, 4-age-group, department-name\n",
        "\n",
        "# df['Age3g'] = df['Age'] // 10 // 3\n",
        "# df['Age4g'] = df['Age'] // 10 // 2.5\n",
        "# dlabels = list(set(df['Department Name']))\n",
        "# dlabels = {d: i for i, d in enumerate(dlabels)}\n",
        "# df['DepCode'] = [dlabels[n] for n in df['Department Name']]\n",
        "\n",
        "####\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "      <th>Atext</th>\n",
              "      <th>Dec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>767</td>\n",
              "      <td>33</td>\n",
              "      <td></td>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Initmates</td>\n",
              "      <td>Intimate</td>\n",
              "      <td>Intimates</td>\n",
              "      <td>Absolutely wonderful - silky and sexy and com...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1080</td>\n",
              "      <td>34</td>\n",
              "      <td></td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happen...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1077</td>\n",
              "      <td>60</td>\n",
              "      <td>Some major design flaws</td>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Some major design flaws I had such high hopes ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1049</td>\n",
              "      <td>50</td>\n",
              "      <td>My favorite buy!</td>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Bottoms</td>\n",
              "      <td>Pants</td>\n",
              "      <td>My favorite buy! I love, love, love this jumps...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>847</td>\n",
              "      <td>47</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Blouses</td>\n",
              "      <td>Flattering shirt This shirt is very flattering...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Clothing ID  Age  ...                                              Atext Dec\n",
              "0          767   33  ...   Absolutely wonderful - silky and sexy and com...   7\n",
              "1         1080   34  ...   Love this dress!  it's sooo pretty.  i happen...   7\n",
              "2         1077   60  ...  Some major design flaws I had such high hopes ...   4\n",
              "3         1049   50  ...  My favorite buy! I love, love, love this jumps...   5\n",
              "4          847   47  ...  Flattering shirt This shirt is very flattering...   5\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkdqbXG-GmlT"
      },
      "source": [
        "Reviewers' age distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoLMH0oAATg9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "cda2ccd8-5426-4675-eb3a-10761d7aedcb"
      },
      "source": [
        "sns.set_style('darkgrid'); sns.displot(df['Dec'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f7d213ba0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDJThMbYD-Co"
      },
      "source": [
        "Description of lengths of normalized texts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grRvom9SGbg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74af2765-8c6f-4a8a-89b1-274edc1d3826"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "STOP_SET = set(stopwords.words('english'))    \n",
        "REPLACE_BY_SPACE = re.compile(r'[/(){}\\[\\]\\|@.,;]')\n",
        "GOOD_SYMBOLS = re.compile(r'[^0-9a-z !?]')\n",
        "PUNCT_SPACE = re.compile(r'([!?])')\n",
        "EXTRA_SPACE = re.compile(r'\\s+')\n",
        "\n",
        "def text_prepare(s):\n",
        "    s = s.lower()\n",
        "    s = REPLACE_BY_SPACE.sub(' ', s)\n",
        "    s = GOOD_SYMBOLS.sub('', s)\n",
        "    s = ' '.join([w for w in s.split() \n",
        "                    if w and w not in STOP_SET])\n",
        "    s = PUNCT_SPACE.sub(r' \\1 ', s)\n",
        "    s = EXTRA_SPACE.sub(' ', s)\n",
        "    return s.strip()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8KQQTtEOT2u"
      },
      "source": [
        "df['Prep'] = [text_prepare(s) for s in df['Atext']]\n",
        "df['Len'] = [len(s.split()) for s in df['Prep']]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fh3QeGnfIQP"
      },
      "source": [
        "Text lengths (max, mean, std) and S/W ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viHi53PFc6zx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0abe295-be8e-4795-f5fa-511904958ce1"
      },
      "source": [
        "print('Prepared text lengths:\\n\\tmax = %d\\n\\tmean = %.2f\\n\\tstd = %.2f' %\n",
        "      (df['Len'].max(), df['Len'].mean(), df['Len'].std()))\n",
        "print('\\n(# of samples / # of words per sample): %.2f' % \n",
        "      (len(df) / df['Len'].mean()))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prepared text lengths:\n",
            "\tmax = 77\n",
            "\tmean = 31.62\n",
            "\tstd = 15.34\n",
            "\n",
            "(# of samples / # of words per sample): 742.77\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjlmwaVPe599"
      },
      "source": [
        "The age group doesn't seem to correlate with the text length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-LkltBcNruc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "b3ec195e-a2ab-443b-d1c0-bf5a989b92c3"
      },
      "source": [
        "sns.lineplot(data=df, x='Dec', y='Len')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7c71d5cba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN1mZyiaaqfh"
      },
      "source": [
        "## 2. Data splits\n",
        "Train 70% - Val 15% - Test 15% (16k, 3.5k, 3.5k)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6oz9l7Aheg9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3aea5d4-b6ed-44e1-8be3-03970b9c9014"
      },
      "source": [
        "## get the test set indices and the rest\n",
        "source_col = 'Prep'\n",
        "target_col = 'Dec'\n",
        "random_state = 1\n",
        "idx_, idx_test = next(SSSplit(n_splits=1, \n",
        "                      test_size=0.15, \n",
        "                      random_state=random_state).split(df[source_col], \n",
        "                                                       df[target_col]))\n",
        "X_test, y_test = df[source_col][idx_test], df[target_col][idx_test]\n",
        "\n",
        "## get the (train + val) sets\n",
        "X_train_val, y_train_val = df[source_col][idx_], df[target_col][idx_]\n",
        "num_classes = len(set(y_train_val))\n",
        "print('Class label set:', set(y_train_val))\n",
        "\n",
        "idx_train, idx_val = next(\n",
        "    SSSplit(n_splits=1, \n",
        "            test_size=15 / 85, \n",
        "            random_state=random_state).split(X_train_val, \n",
        "                                             y_train_val))\n",
        "X_train, y_train = df[source_col][idx_train], df[target_col][idx_train]\n",
        "X_val, y_val = df[source_col][idx_val], df[target_col][idx_val]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class label set: {0, 1, 2, 3, 4, 5, 6, 7, 8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ_Jy65_VLTS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "801fe8dd-8736-43a5-e55f-966d5c77e2e0"
      },
      "source": [
        "for i in range(5):\n",
        "    print('\"%s...\"' % X_train.iloc[i][:50], y_train.iloc[i])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"great classic boyfriend jean distressed bought sto...\" 7\n",
            "\"unique love unique tshirt fall colors ranchers the...\" 5\n",
            "\"best shirt ever bought colors wish could buy color...\" 7\n",
            "\"dont miss top great top worth money nice flow soft...\" 5\n",
            "\"cute romper material meh cute romper love pattern ...\" 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4GQhWF1AQ1m"
      },
      "source": [
        "## 3. Baseline\n",
        "Since S/W ratio is less than 1500 (see [this recommendation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5?hl=en)), it makes sense to try n-gram bag-of-words models. These baseline models give a sense about at least how much better we can do than guessing randomly or by the mode (70s)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkCJtcwE_Fc1"
      },
      "source": [
        "def guessMode(input, mode=6):\n",
        "    return np.array([mode] * input.shape[0])\n",
        "\n",
        "def guessRandom(input, lo=0, hi=8):\n",
        "    return np.random.randint(lo, hi + 1, input.shape[0])\n",
        "\n",
        "def model_assess(title, y_true, y_pred):\n",
        "    print('%s:\\n' % title,\n",
        "        'MAE: %.3f' % MAE(y_true, y_pred),\n",
        "        'Acc: %.3f' % accuracy_score(y_true, y_pred),\n",
        "        'F1: %.3f' % f1_score(y_true, y_pred, average='micro'), \n",
        "        end='\\n\\n')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT59pkph_vvK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04009187-72bb-4ef6-f7fb-3f9a3da84698"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(min_df=5, max_df=0.9, \n",
        "                                   ngram_range=(1, 2),\n",
        "                                   token_pattern='(\\S+)')\n",
        "\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf =  tfidf_vectorizer.transform(X_val)\n",
        "X_test_tfidf =  tfidf_vectorizer.transform(X_test)\n",
        "print('TFIDF vocab size', len(tfidf_vectorizer.vocabulary_))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TFIDF vocab size 19696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyqXJq_n0jbD"
      },
      "source": [
        "It is reported [here](https://rikunert.com/ordinal_rating) that ordinal classification (e.g. ratings) are better served by *ordered logistic regression* (LAT) than by *logistic regressions* (LR).  \n",
        "* features of 90s are closer to features of 80s than those of 50s;\n",
        "* predicting 90s for 80s is better than predicting 50s.\n",
        "\n",
        "Both LAT & LR are experiemnted.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIEQE-_WBx5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f300318-cbc4-47fb-c4ed-40f154401dc3"
      },
      "source": [
        "clf_LR = LogisticRegression(C=1, max_iter=1000)\n",
        "clf_LAT = LogisticAT(alpha=0.01, verbose=1, max_iter=10000)\n",
        "clf_LR.fit(X_train_tfidf, y_train)\n",
        "clf_LAT.fit(X_train_tfidf, y_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticAT(alpha=0.01, max_iter=10000, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD7br4LbQ1W7"
      },
      "source": [
        "n-grams models fare slightly better than guessing, but underfit even when minimizing regularization coef. \n",
        "For this particular task, it seems that ignoring the ordinal nature of the labels doesn't hurt much. **Thus the following deep models go with multiclass classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAVVxe8ZI2Wn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a30fff-c7ac-4255-d6c9-4673ee14f906"
      },
      "source": [
        "model_assess('OrdLogiAT - train', \n",
        "             y_train, clf_LAT.predict(X_train_tfidf))\n",
        "model_assess('OrdLogiAT - val', \n",
        "             y_val, clf_LAT.predict(X_val_tfidf))\n",
        "model_assess('LogiReg - train', \n",
        "             y_train, clf_LR.predict(X_train_tfidf))\n",
        "model_assess('LogiReg - val', \n",
        "             y_val, clf_LR.predict(X_val_tfidf))\n",
        "model_assess('Guess mode - val', \n",
        "             y_val, guessMode(X_val_tfidf))\n",
        "model_assess('Guess random - val', \n",
        "             y_val, guessRandom(X_val_tfidf))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrdLogiAT - train:\n",
            " MAE: 0.111 Acc: 0.895 F1: 0.895\n",
            "\n",
            "OrdLogiAT - val:\n",
            " MAE: 1.331 Acc: 0.236 F1: 0.236\n",
            "\n",
            "LogiReg - train:\n",
            " MAE: 0.577 Acc: 0.660 F1: 0.660\n",
            "\n",
            "LogiReg - val:\n",
            " MAE: 0.991 Acc: 0.343 F1: 0.343\n",
            "\n",
            "Guess mode - val:\n",
            " MAE: 0.984 Acc: 0.306 F1: 0.306\n",
            "\n",
            "Guess random - val:\n",
            " MAE: 2.796 Acc: 0.104 F1: 0.104\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJw29RzJiC4z",
        "outputId": "93a9b5d4-f960-4f12-b9f3-298113b8818c"
      },
      "source": [
        "# class distribution checking\n",
        "print(Counter(y_val).most_common())\n",
        "print(Counter(clf_LAT.predict(X_val_tfidf)).most_common())\n",
        "print(Counter(clf_LR.predict(X_val_tfidf)).most_common())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(6, 1078), (7, 936), (5, 671), (4, 461), (8, 224), (3, 128), (2, 21), (1, 4)]\n",
            "[(6, 1064), (7, 798), (5, 663), (4, 440), (8, 362), (3, 156), (2, 32), (1, 6), (0, 2)]\n",
            "[(6, 1857), (7, 1081), (5, 476), (4, 103), (8, 6)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs_Xb-9i5qY8"
      },
      "source": [
        "## 4. Deep models\n",
        "Since the baseline capacity is insufficient, we experiment with deep models:\n",
        "*   Basic CNN (with frozen GloVe embedding)\n",
        "*   Separable CNN\n",
        "*   Transformer\n",
        "\n",
        "These are parallizable & computationally efficient.  \n",
        "The next step can be character-level CNN, large-scale pretrained encoder (BERT), recurrent networks ...\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV0WQHn2A2Ym"
      },
      "source": [
        "#### build vocabulary & tokenzier\n",
        "MAX_LEN = 60                # roughly (mean + 2 * std)\n",
        "MAX_VOCAB_SIZE = 2 ** 14    # comparable to TFIDF vocab size\n",
        "\n",
        "tokenizer = prep.text.Tokenizer(\n",
        "    num_words=MAX_VOCAB_SIZE,\n",
        "    filters='\"#$%&()*+.,-/:;<=>@[\\\\]^_`{|}~\\t\\n')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "vocab_size = min(MAX_VOCAB_SIZE, len(tokenizer.word_index) + 1)\n",
        "\n",
        "X_train_vec = tokenizer.texts_to_sequences(X_train)\n",
        "max_len = len(max(X_train_vec, key=len))\n",
        "max_len = min(MAX_LEN, max_len)\n",
        "X_train_vec = prep.sequence.pad_sequences(X_train_vec, maxlen=max_len)\n",
        "\n",
        "X_val_vec = tokenizer.texts_to_sequences(X_val)\n",
        "X_val_vec = prep.sequence.pad_sequences(X_val_vec, maxlen=max_len)\n",
        "\n",
        "X_test_vec = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_vec = prep.sequence.pad_sequences(X_test_vec, maxlen=max_len)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz_d-493OC0X"
      },
      "source": [
        "def get_opt():\n",
        "    return tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=3)]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puJYw8YKR2M-"
      },
      "source": [
        "### 4.1 Basic CNN\n",
        "As described in [here](https://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf) and [here](https://arxiv.org/pdf/1408.5882.pdf) (with frozen GloVe embedding).  \n",
        "GloVe + \"basic\" models won't benifit much from tuable embedding (Sam Bowman p.c.). Experimented and confirmed (results omitted)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z015msscxBhU"
      },
      "source": [
        "SPACY_EMB_SIZE = 300\n",
        "emb_matrix = np.zeros((vocab_size, SPACY_EMB_SIZE))\n",
        "for w, i in tokenizer.word_index.items():\n",
        "    emb_matrix[i] = spacy_nlp(w).vector"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2nR7SoYyUrv"
      },
      "source": [
        "def build_cnn_model(embedding_dim,\n",
        "                    num_classes,\n",
        "                    num_features,\n",
        "                    input_shape,\n",
        "                    filters=100,\n",
        "                    hidden_dim=256,\n",
        "                    dropout_rate=0.2):\n",
        "    t_in = L.Input(shape=input_shape, dtype='int64')\n",
        "    embedding = L.Embedding(\n",
        "        input_dim=num_features,\n",
        "        output_dim=embedding_dim,\n",
        "        embeddings_initializer=initializers.Constant(emb_matrix),\n",
        "        trainable=False)(t_in)\n",
        "    \n",
        "    tri_gram = L.Conv1D(filters, 3, padding='same', \n",
        "                        activation='relu')(embedding)\n",
        "    tri_gram = L.GlobalMaxPooling1D()(tri_gram)\n",
        "    \n",
        "    quart_gram = L.Conv1D(filters, 4, padding='same', \n",
        "                          activation='relu')(embedding)\n",
        "    quart_gram = L.GlobalMaxPooling1D()(quart_gram)\n",
        "    \n",
        "    quint_gram = L.Conv1D(filters, 5, padding='same', \n",
        "                          activation='relu')(embedding)\n",
        "    quint_gram = L.GlobalMaxPooling1D()(quint_gram)\n",
        "\n",
        "    concat = L.Concatenate(axis=1)([tri_gram, quart_gram, quint_gram])\n",
        "    t_den = L.Dense(hidden_dim, activation='relu')(concat)\n",
        "    t_den = L.Dropout(dropout_rate)(t_den)\n",
        "    t_out = L.Dense(num_classes, activation='softmax')(t_den)\n",
        "    model = models.Model(t_in, t_out)\n",
        "    return model\n",
        "\n",
        "model_cnn = build_cnn_model(\n",
        "    embedding_dim=SPACY_EMB_SIZE,\n",
        "    num_classes=num_classes,\n",
        "    num_features=vocab_size,\n",
        "    input_shape=[max_len],\n",
        "    dropout_rate=0.5)\n",
        "\n",
        "model_cnn.compile(optimizer=get_opt(),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['acc'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOC4XqeLRise",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc108d77-0d92-45d5-daed-b17cd0e26840"
      },
      "source": [
        "model_cnn.fit(\n",
        "    X_train_vec,\n",
        "    y_train,                     \n",
        "    epochs=40,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=(X_val_vec, y_val), \n",
        "    verbose=1, # progress bar  \n",
        "    batch_size=128)\n",
        "print('Trainning stopped.')\n",
        "model_cnn.save(os.path.join(home_path, 'text2dec_cnn_model.h5'))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "129/129 [==============================] - 2s 13ms/step - loss: 1.7129 - acc: 0.2903 - val_loss: 1.6453 - val_acc: 0.3071\n",
            "Epoch 2/40\n",
            "129/129 [==============================] - 1s 10ms/step - loss: 1.6094 - acc: 0.3220 - val_loss: 1.6170 - val_acc: 0.3111\n",
            "Epoch 3/40\n",
            "129/129 [==============================] - 1s 10ms/step - loss: 1.5532 - acc: 0.3420 - val_loss: 1.6059 - val_acc: 0.3137\n",
            "Epoch 4/40\n",
            "129/129 [==============================] - 1s 10ms/step - loss: 1.4746 - acc: 0.3835 - val_loss: 1.6127 - val_acc: 0.3185\n",
            "Epoch 5/40\n",
            "129/129 [==============================] - 1s 10ms/step - loss: 1.3360 - acc: 0.4515 - val_loss: 1.6784 - val_acc: 0.2944\n",
            "Epoch 6/40\n",
            "129/129 [==============================] - 1s 10ms/step - loss: 1.1191 - acc: 0.5608 - val_loss: 1.8061 - val_acc: 0.2733\n",
            "Trainning stopped.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahlAoMTmO4rG"
      },
      "source": [
        "### 4.2 sepCNN \n",
        "[Depthwise Separable Convolutional Network](https://arxiv.org/abs/1610.02357), recommended [here](https://developers.google.com/machine-learning/guides/text-classification/step-4), where an implementation is given."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpmfUQZ9K-d2"
      },
      "source": [
        "def build_sepcnn_model(filters,\n",
        "                       kernel_size,\n",
        "                       embedding_dim,\n",
        "                       dropout_rate,\n",
        "                       pool_size,\n",
        "                       input_shape,\n",
        "                       num_classes,\n",
        "                       num_features):\n",
        "    \n",
        "    model = models.Sequential()\n",
        "    model.add(L.Embedding(input_dim=num_features,\n",
        "                          output_dim=embedding_dim,\n",
        "                          input_length=input_shape[0]))\n",
        "\n",
        "    model.add(L.Dropout(rate=dropout_rate))\n",
        "    model.add(L.SeparableConv1D(filters=filters,\n",
        "                                kernel_size=kernel_size,\n",
        "                                activation='relu',\n",
        "                                bias_initializer='random_uniform',\n",
        "                                depthwise_initializer='random_uniform',\n",
        "                                padding='same'))\n",
        "    model.add(L.SeparableConv1D(filters=filters,\n",
        "                                kernel_size=kernel_size,\n",
        "                                activation='relu',\n",
        "                                bias_initializer='random_uniform',\n",
        "                                depthwise_initializer='random_uniform',\n",
        "                                padding='same'))\n",
        "    model.add(L.MaxPooling1D(pool_size=pool_size))\n",
        "    \n",
        "    model.add(L.SeparableConv1D(filters=filters * 2,\n",
        "                               kernel_size=kernel_size,\n",
        "                               activation='relu',\n",
        "                               bias_initializer='random_uniform',\n",
        "                               depthwise_initializer='random_uniform',\n",
        "                               padding='same'))\n",
        "    model.add(L.SeparableConv1D(filters=filters * 2,\n",
        "                                kernel_size=kernel_size,\n",
        "                                activation='relu',\n",
        "                                bias_initializer='random_uniform',\n",
        "                                depthwise_initializer='random_uniform',\n",
        "                                padding='same'))\n",
        "    model.add(L.GlobalAveragePooling1D())\n",
        "\n",
        "    model.add(L.Dropout(rate=dropout_rate))\n",
        "    model.add(L.Dense(num_classes, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "model_sepcnn = build_sepcnn_model(\n",
        "    filters=64,\n",
        "    embedding_dim=256,\n",
        "    kernel_size=3,\n",
        "    pool_size=3,\n",
        "    dropout_rate=0.2,\n",
        "    input_shape=[max_len],\n",
        "    num_classes=num_classes,\n",
        "    num_features=vocab_size)\n",
        "\n",
        "model_sepcnn.compile(optimizer=get_opt(),\n",
        "                     loss='sparse_categorical_crossentropy',\n",
        "                     metrics=['acc'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvVMW_e0XpTE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cfa74d4-02cf-4387-be24-645b921e3463"
      },
      "source": [
        "model_sepcnn.fit(\n",
        "    X_train_vec,\n",
        "    y_train,                            \n",
        "    epochs=40,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=(X_val_vec, y_val), \n",
        "    verbose=1, # progress bar  \n",
        "    batch_size=128)\n",
        "print('Trainning stopped.')\n",
        "model_sepcnn.save(os.path.join(home_path, 'text2dec_sepcnn_model.h5'))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "129/129 [==============================] - 6s 44ms/step - loss: 1.8304 - acc: 0.3036 - val_loss: 1.6419 - val_acc: 0.3060\n",
            "Epoch 2/40\n",
            "129/129 [==============================] - 5s 42ms/step - loss: 1.6284 - acc: 0.3060 - val_loss: 1.6361 - val_acc: 0.3060\n",
            "Epoch 3/40\n",
            "129/129 [==============================] - 5s 41ms/step - loss: 1.6217 - acc: 0.3065 - val_loss: 1.6226 - val_acc: 0.3060\n",
            "Epoch 4/40\n",
            "129/129 [==============================] - 5s 41ms/step - loss: 1.5838 - acc: 0.3107 - val_loss: 1.6100 - val_acc: 0.2969\n",
            "Epoch 5/40\n",
            "129/129 [==============================] - 5s 42ms/step - loss: 1.5212 - acc: 0.3352 - val_loss: 1.6370 - val_acc: 0.3046\n",
            "Epoch 6/40\n",
            "129/129 [==============================] - 5s 41ms/step - loss: 1.4530 - acc: 0.3611 - val_loss: 1.6754 - val_acc: 0.3034\n",
            "Epoch 7/40\n",
            "129/129 [==============================] - 5s 41ms/step - loss: 1.3764 - acc: 0.3903 - val_loss: 1.7658 - val_acc: 0.3006\n",
            "Trainning stopped.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBP0NgAAmDtR"
      },
      "source": [
        "### 4.3 Transformer\n",
        "Implementation found [here](https://keras.io/examples/nlp/text_classification_with_transformer/), with modification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Biujr8zdmRYb"
      },
      "source": [
        "class MultiHeadSelfAttention(L.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads:\n",
        "            raise ValueError('embedding dimension indivisible by # of heads')\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = L.Dense(embed_dim)\n",
        "        self.key_dense = L.Dense(embed_dim)\n",
        "        self.value_dense = L.Dense(embed_dim)\n",
        "        self.combine_heads = L.Dense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, \n",
        "                           self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(inputs)      # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(\n",
        "            query, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        key = self.separate_heads(\n",
        "            key, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(\n",
        "            value, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(\n",
        "            attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.embed_dim)\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(\n",
        "            concat_attention\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        return output\n",
        "\n",
        "\n",
        "class TransformerBlock(L.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = models.Sequential(\n",
        "            [L.Dense(ff_dim, activation=\"relu\"), L.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = L.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = L.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = L.Dropout(rate)\n",
        "        self.dropout2 = L.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "\n",
        "class TokenAndPositionEmbedding(L.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.token_emb = L.Embedding(input_dim=vocab_size, \n",
        "                                     output_dim=embed_dim)\n",
        "        self.pos_emb = L.Embedding(input_dim=maxlen, \n",
        "                                   output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions\n",
        "\n",
        "\n",
        "def build_transformer_model(\n",
        "    input_shape,\n",
        "    num_features,\n",
        "    num_classes,\n",
        "    embed_dim,    \n",
        "    num_heads=2,  \n",
        "    ff_dim=32,\n",
        "    hidden_dim=32):\n",
        "\n",
        "    t_in = L.Input(shape=input_shape)\n",
        "    embedding_layer = TokenAndPositionEmbedding(input_shape[0], \n",
        "                                                num_features, \n",
        "                                                embed_dim)\n",
        "    emb = embedding_layer(t_in)\n",
        "    t = TransformerBlock(embed_dim, num_heads, ff_dim)(emb)\n",
        "    t = L.GlobalAveragePooling1D()(t)\n",
        "    t = L.Dropout(0.1)(t)\n",
        "    t = L.Dense(hidden_dim, activation='relu')(t)\n",
        "    t = L.Dropout(0.1)(t)\n",
        "    t_out = L.Dense(num_classes, activation='softmax')(t)\n",
        "\n",
        "    model = models.Model(t_in, t_out)\n",
        "    return model\n",
        "\n",
        "model_transf = build_transformer_model(\n",
        "    input_shape=[max_len],\n",
        "    num_features=vocab_size,\n",
        "    num_classes=num_classes,\n",
        "    embed_dim=128)\n",
        "\n",
        "model_transf.compile(optimizer=get_opt(),\n",
        "                     loss='sparse_categorical_crossentropy',\n",
        "                     metrics=['acc'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RavMgpodsFtI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a6c8842-95c3-4201-c301-ca594ac96f65"
      },
      "source": [
        "model_transf.fit(\n",
        "    X_train_vec,\n",
        "    y_train ,                            \n",
        "    epochs=40,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=(X_val_vec, y_val),\n",
        "    verbose=1, # progress bar  \n",
        "    batch_size=128)\n",
        "print('Trainning stopped.')\n",
        "model_sepcnn.save(os.path.join(home_path, 'text2dec_transf_model.h5'))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "129/129 [==============================] - 4s 31ms/step - loss: 1.6924 - acc: 0.2830 - val_loss: 1.6032 - val_acc: 0.3256\n",
            "Epoch 2/40\n",
            "129/129 [==============================] - 4s 28ms/step - loss: 1.5386 - acc: 0.3679 - val_loss: 1.5843 - val_acc: 0.3287\n",
            "Epoch 3/40\n",
            "129/129 [==============================] - 4s 29ms/step - loss: 1.3469 - acc: 0.4732 - val_loss: 1.7078 - val_acc: 0.3349\n",
            "Epoch 4/40\n",
            "129/129 [==============================] - 4s 28ms/step - loss: 1.1065 - acc: 0.5724 - val_loss: 1.8790 - val_acc: 0.3244\n",
            "Epoch 5/40\n",
            "129/129 [==============================] - 4s 28ms/step - loss: 0.8510 - acc: 0.6749 - val_loss: 2.4360 - val_acc: 0.3040\n",
            "Trainning stopped.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2aRrvgE_QHe"
      },
      "source": [
        "It turns out that these deep models \n",
        "*   fit the training examples well (actually training loss keeps decreasing if more epochs trained)\n",
        "*   quickly become overfitted (val loss doesn't improve correspondingly)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHNv3vVf-dzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d5ab27a-019d-47b1-cf4c-d58553d52427"
      },
      "source": [
        "model_assess('Basic CNN - val', \n",
        "             y_val, np.argmax(model_cnn.predict(X_val_vec), axis=1))\n",
        "model_assess('SepCNN - val', \n",
        "             y_val, np.argmax(model_sepcnn.predict(X_val_vec), axis=1))\n",
        "model_assess('Transformer - val', \n",
        "             y_val, np.argmax(model_transf.predict(X_val_vec), axis=1))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Basic CNN - val:\n",
            " MAE: 1.189 Acc: 0.273 F1: 0.273\n",
            "\n",
            "SepCNN - val:\n",
            " MAE: 1.050 Acc: 0.301 F1: 0.301\n",
            "\n",
            "Transformer - val:\n",
            " MAE: 1.171 Acc: 0.304 F1: 0.304\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nhqme3eChGls",
        "outputId": "088fbb64-c8b1-460c-e075-b5d8c707ff48"
      },
      "source": [
        "# class distribution checking\n",
        "print(Counter(y_val).most_common())\n",
        "print(Counter(np.argmax(model_cnn.predict(X_val_vec), axis=1)).most_common())\n",
        "print(Counter(np.argmax(model_sepcnn.predict(X_val_vec), axis=1)).most_common())\n",
        "print(Counter(np.argmax(model_transf.predict(X_val_vec), axis=1)).most_common())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(6, 1078), (7, 936), (5, 671), (4, 461), (8, 224), (3, 128), (2, 21), (1, 4)]\n",
            "[(5, 1150), (7, 1075), (6, 777), (4, 517), (8, 4)]\n",
            "[(6, 1787), (5, 920), (7, 716), (4, 100)]\n",
            "[(6, 1223), (7, 866), (5, 641), (4, 462), (8, 207), (3, 119), (2, 5)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_Uls69DAhBz"
      },
      "source": [
        "## 5. Summary\n",
        "\n",
        "1.  A small dataset. Deep models' overfitting pattern suggests generalization may improve on larger datasets.\n",
        "\n",
        "2. Techniques to scale: character-level CNN ([here](https://arxiv.org/pdf/1509.01626.pdf)), hashing vectorizer \n",
        "\n",
        "3.   If we reduce the number of age groups (3-4 groups), the performance improves on this dataset (val-acc 0.5-0.7). Previous studies on \"age prediction\" usually handle 2-5 classes (e.g. [[1]](https://arxiv.org/pdf/1610.00852.pdf), [[2]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7932459), [[3]](https://www.aclweb.org/anthology/P17-2076.pdf)).\n",
        "\n",
        "4.   Two predictors: contents and styles. But now the domain is limited to clothing review (not able to distinguish ages by topic), and the genre is set as review (there might be spelling clues --- need sub-word encoding to pick up)\n",
        "\n",
        "5.   No clear correlation between age & item type distribution (e.g. tops and dresses are popular for all ages) --- confirmed by experiment: these model perform reasonably well on \"department name\" classification, val-acc > 0.8.\n",
        "\n",
        "\n"
      ]
    }
  ]
}