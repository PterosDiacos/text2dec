{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text2Dec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8LHD9vlayJn"
      },
      "source": [
        "## 0. Logistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xLDqEM94U1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6500f6d9-2763-496d-dfd7-0f4b2ebd74ba"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3qM2H55CCK3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbdcd543-58e3-47fd-8f7c-c6107b30d8ae"
      },
      "source": [
        "!pip install mord\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mord in /usr/local/lib/python3.6/dist-packages (0.6)\n",
            "Requirement already satisfied: en_core_web_lg==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz#egg=en_core_web_lg==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajEtSZE_9WaM"
      },
      "source": [
        "import os\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from mord import LogisticAT\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, accuracy_score, \\\n",
        "                            mean_absolute_error as MAE\n",
        "from sklearn.model_selection import cross_val_score, \\\n",
        "                                    StratifiedShuffleSplit as SSSplit\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import preprocessing as prep\n",
        "from tensorflow.python.keras import models, initializers\n",
        "from tensorflow.python.keras import layers as L                                    \n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6-LlBFSAlQQ"
      },
      "source": [
        "spacy_nlp = spacy.load('en_core_web_lg')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE_RnjpV6bPl"
      },
      "source": [
        "home_path = '/content/drive/My Drive/Colab Notebooks/assgn'\n",
        "data_path = os.path.join(home_path, 'original.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgKbWa9vjlVr"
      },
      "source": [
        "# Texts to Decades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX-Uc0KTxZvz"
      },
      "source": [
        "Task: predict the reviewer’s birth decade (90’s, 80’s, 00’s, etc)  using only text features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf_xTYknBDSv"
      },
      "source": [
        "## 1. Data exploration\n",
        "The dataset was web-scraped around 2016 ([dataset author's post](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews/discussion/65898)). `Atext` concats `Title` and `Review Text`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrszQNH29rjM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "b78b91cc-1b91-427a-9ba7-91ccd64fd75d"
      },
      "source": [
        "df = pd.read_csv(data_path, index_col=0)\n",
        "df.fillna('', inplace=True)\n",
        "df['Atext'] = df['Title'] + ' ' + df['Review Text']\n",
        "## age should be in (6, 106]; shift decades from [1, 9] to [0, 8]\n",
        "df['Dec'] = (2016 - df['Age'] - 1900) // 10 - 1  \n",
        "\n",
        "#### other prediction targets to explore:\n",
        "#### 3-age-group, 4-age-group, department-name\n",
        "\n",
        "# df['Age3g'] = df['Age'] // 10 // 3\n",
        "# df['Age4g'] = df['Age'] // 10 // 2.5\n",
        "# dlabels = list(set(df['Department Name']))\n",
        "# dlabels = {d: i for i, d in enumerate(dlabels)}\n",
        "# df['DepCode'] = [dlabels[n] for n in df['Department Name']]\n",
        "\n",
        "####\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "      <th>Atext</th>\n",
              "      <th>Dec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>767</td>\n",
              "      <td>33</td>\n",
              "      <td></td>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Initmates</td>\n",
              "      <td>Intimate</td>\n",
              "      <td>Intimates</td>\n",
              "      <td>Absolutely wonderful - silky and sexy and com...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1080</td>\n",
              "      <td>34</td>\n",
              "      <td></td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happen...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1077</td>\n",
              "      <td>60</td>\n",
              "      <td>Some major design flaws</td>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Some major design flaws I had such high hopes ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1049</td>\n",
              "      <td>50</td>\n",
              "      <td>My favorite buy!</td>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Bottoms</td>\n",
              "      <td>Pants</td>\n",
              "      <td>My favorite buy! I love, love, love this jumps...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>847</td>\n",
              "      <td>47</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Blouses</td>\n",
              "      <td>Flattering shirt This shirt is very flattering...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Clothing ID  Age  ...                                              Atext Dec\n",
              "0          767   33  ...   Absolutely wonderful - silky and sexy and com...   7\n",
              "1         1080   34  ...   Love this dress!  it's sooo pretty.  i happen...   7\n",
              "2         1077   60  ...  Some major design flaws I had such high hopes ...   4\n",
              "3         1049   50  ...  My favorite buy! I love, love, love this jumps...   5\n",
              "4          847   47  ...  Flattering shirt This shirt is very flattering...   5\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkdqbXG-GmlT"
      },
      "source": [
        "Reviewers' age distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoLMH0oAATg9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "ff09c57d-5e10-4951-a0ee-23cc942519c5"
      },
      "source": [
        "sns.set_style('darkgrid'); sns.displot(df['Dec'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7fc3a8499128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAYAAACFYaNMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df1DUd2L/8eeHz6KH8mMDwm70GL+jSa4ZvWg7vSiB0xFnwQSJmIPmmptO5XJjq/asMck1JuePRiXtjJcyN0zb0LQ57ztp7pQTuB7XSIREIJpLJqelidfLpVajGXf3KxEQNMIun+8fhK2exENkP2/B12PGyfKW9+f9QtaXm/d+Ph8sx3EcRETEdQmmA4iI3KpUwCIihqiARUQMUQGLiBiiAhYRMcRjOkA89PVF6Oq6eN3zkpMn09NzKQ6JlEEZxncOZbixDJmZKcOOT8hXwJZljWqex2OPcRJlUIYbdzPkUIb4ZJiQBSwiMh6ogEVEDFEBi4gYogIWETFEBSwiYogKWETEEBWwiIghKmAREUNUwCIihqiARUQMUQGLiBiiAhYRMUQFLCKfKzHRJjHRxrIGH8vYmpC3oxSRG5eYaFPTfoaTZ3uxPQl80ZtE6T23098fNR1twlABi8jnOnm2l2NnuvF4bKKRAdNxJhxtQYiIGKICFhExRAUsImKIClhExBAVsIiIIXEr4OPHj7NixYrYrz/4gz/gBz/4AZ2dnZSXl1NQUEB5eTldXV0AOI7Djh07CAQCFBcX8/7778eOVVtbS0FBAQUFBdTW1sYrsoiIq+JWwLNmzaK+vp76+nr27dtHUlISgUCA6upqcnJyaGxsJCcnh+rqagBaWlo4ceIEjY2NbN++nW3btgHQ2dlJVVUVe/bsYe/evVRVVcVKW0RkPHNlC+Lw4cNkZ2czY8YMmpqaKCkpAaCkpIQDBw4AxMYty2L+/Pl0d3cTDodpa2sjNzcXr9dLWloaubm5tLa2uhFbRCSuXCnghoYGli9fDkBHRwdZWVkAZGZm0tHRAUAoFMLv98fm+P1+QqHQVeM+n49QKORGbBGRuIr7lXB9fX00Nzfz+OOPX/V7lmVhWdaYr2nbFl7vlFHMSxjVvLGkDMpws+SwLLA9CXg8NhaDj5OTJ+M4rkcBbo7vx1hniHsBt7S0MGfOHKZNmwZARkYG4XCYrKwswuEw6enpwOAr22AwGJsXDAbx+Xz4fD7efvvt2HgoFOLee++95prRqENn54Xrzur1ThnVvLGkDMpws+RITBy8/DgSicYuRe7puWTsXhA3w/djtBkyM1OGHY/7FkRDQwNFRUWxj/Pz86mrqwOgrq6OpUuXXjHuOA5Hjx4lJSWFrKws8vLyaGtro6uri66uLtra2sjLy4t3bBGRuIvrK+ALFy5w6NAhnn322djY6tWr2bBhAzU1NUyfPp3KykoAFi9ezMGDBwkEAiQlJVFRUQGA1+tl7dq1lJaWArBu3Tq8Xm88Y4uIuMJyHFM7OvHT3x/VFoQyTIgMJnMkJtp8r/nD2N3Q7sqcyuP5d2gLYjxtQYiIyPBUwCIihqiARUQMUQGLiBiiAhYRMUQFLCJiiApYRMQQFbCIiCEqYBERQ1TAIiKGqIBFRAxRAYuIGKICFhExRAUsImKIClhExBAVsIiIISpgERFDVMAiIoaogEVEDFEBi4gYogIWETFEBSwiYogKWETEEBWwiIghKmAREUNUwCIihqiARUQM8ZgOICLyeRIT7dhjyzIYJE5UwCJyU0pMtKlpP8PJs70AzMpKYeVcH/39UcPJxo4KWERuWifP9nLsTDcAtmfi7ZhOvK9IRGScUAGLiBgS1wLu7u5m/fr1LFu2jPvvv58jR47Q2dlJeXk5BQUFlJeX09XVBYDjOOzYsYNAIEBxcTHvv/9+7Di1tbUUFBRQUFBAbW1tPCOLiLgmrgW8c+dOvvrVr/Lqq69SX1/P7Nmzqa6uJicnh8bGRnJycqiurgagpaWFEydO0NjYyPbt29m2bRsAnZ2dVFVVsWfPHvbu3UtVVVWstEVExrO4FfD58+d55513KC0tBWDSpEmkpqbS1NRESUkJACUlJRw4cAAgNm5ZFvPnz6e7u5twOExbWxu5ubl4vV7S0tLIzc2ltbU1XrFFRFwTt7MgTp8+TXp6Ops2beK//uu/mDNnDs888wwdHR1kZWUBkJmZSUdHBwChUAi/3x+b7/f7CYVCV437fD5CodA117ZtC693ynVntu2EUc0bS8qgDDdLDssaPPPA47GxGHycnDwZx3F//SFurj+csf5exK2AI5EIx44dY/PmzcybN48dO3bEthuGWJaFFYezq6NRh87OC9c9z+udMqp5Y0kZlOFmyZGYaBONDBCJRPF4Bh/39Fxy7Tzcy9cf4ub6wxnt9yIzM2XY8bhtQfj9fvx+P/PmzQNg2bJlHDt2jIyMDMLhMADhcJj09HRg8JVtMBiMzQ8Gg/h8vqvGQ6EQPp8vXrFFRFwTtwLOzMzE7/dz/PhxAA4fPszs2bPJz8+nrq4OgLq6OpYuXQoQG3cch6NHj5KSkkJWVhZ5eXm0tbXR1dVFV1cXbW1t5OXlxSu2iIhr4nol3ObNm3niiSfo7+8nOzub5557joGBATZs2EBNTQ3Tp0+nsrISgMWLF3Pw4EECgQBJSUlUVFQA4PV6Wbt2bezNvHXr1uH1euMZW0TEFXEt4Lvvvpt9+/ZdNb579+6rxizLYuvWrcMep7S0NFbAIiITha6EExExRAUsImKIClhExBAVsIiIISpgERFDVMAiIoaogEVEDFEBi4gYogIWETFEBSwiYogKWETEEBWwiIghKmAREUNUwCIihqiARUQMUQGLiBiiAhYRMUQFLCJiiApYRMQQFbCIiCEqYBERQ1TAIiKGqIBFRAxRAYuIGKICFhExRAUsImKIClhExBAVsIiIISpgERFDVMAiIoaogEVEDPHE8+D5+flMnTqVhIQEbNtm3759dHZ28thjj/Hxxx8zY8YMKisrSUtLw3Ecdu7cycGDB/nCF77A3/zN3zBnzhwAamtr+Yd/+AcA1qxZw8qVK+MZW0TEFXF/Bbx7927q6+vZt28fANXV1eTk5NDY2EhOTg7V1dUAtLS0cOLECRobG9m+fTvbtm0DoLOzk6qqKvbs2cPevXupqqqiq6sr3rFFROLO9S2IpqYmSkpKACgpKeHAgQNXjFuWxfz58+nu7iYcDtPW1kZubi5er5e0tDRyc3NpbW11O7aIyJiL6xYEwKOPPoplWTz88MM8/PDDdHR0kJWVBUBmZiYdHR0AhEIh/H5/bJ7f7ycUCl017vP5CIVC11zTti283inXndW2E0Y1bywpgzLcLDksC2xPAh6PjcXg4+TkyTiO++sPcXP94Yz19yKuBfzKK6/g8/no6OigvLycWbNmXfH7lmVhWdaYrxuNOnR2XrjueV7vlFHNG0vKoAw3S47ERJtoZIBIJIrHM/i4p+cS/f1R19cf4ub6wxnt9yIzM2XY8bhuQfh8PgAyMjIIBAK0t7eTkZFBOBwGIBwOk56eHvvcYDAYmxsMBvH5fFeNh0Kh2HFFRMazuBXwhQsX6OnpiT1+8803ufPOO8nPz6eurg6Auro6li5dChAbdxyHo0ePkpKSQlZWFnl5ebS1tdHV1UVXVxdtbW3k5eXFK7aIiGvitgXR0dHBunXrAIhGoyxfvpxFixbx5S9/mQ0bNlBTU8P06dOprKwEYPHixRw8eJBAIEBSUhIVFRUAeL1e1q5dS2lpKQDr1q3D6/XGK7aIiGviVsDZ2dn89Kc/vWr8tttuY/fu3VeNW5bF1q1bhz1WaWlprIBFRCYKXQknImKIClhExBAVsIiIISpgERFDVMAiIoaogEVEDFEBi4gYogIWuYklJtpY1uB/ExPt3z1BxpW43w1NREYnMdGmpv0MpzsvEo0MMHPaVErvud3ozWhkbKmARW5iJ8/28sH/673ijmAycWgLQkTEEBWwiIghKmAREUNUwCIihqiARUQMUQGLiBiiAhYRMUQFLCJiiApYRMQQFbCIiCEqYBERQ1TAIiKGqIBFRAxRAYuIGKICFhExRAUsImKIClhExBAVsIiIISpgERFDVMAiIoaMqIDffffdEY2JiMjIjaiAd+zYMaKx4USjUUpKSvizP/szAE6dOkVZWRmBQIANGzbQ19cHQF9fHxs2bCAQCFBWVsbp06djx3jhhRcIBAIUFhbS2to6onVFRG521/yx9EeOHOHIkSN88sknvPTSS7Hxnp4eotGR/ZjsH/7wh8yePZuenh4Adu3axapVqygqKmLLli3U1NTwyCOPsHfvXlJTU3nttddoaGhg165dVFZW8uGHH9LQ0EBDQwOhUIjy8nL279+Pbds38GWLiJh3zVfA/f39XLhwgWg0Sm9vb+xXcnIy3//+93/nwYPBIG+88QalpaUAOI7DW2+9RWFhIQArV66kqakJgObmZlauXAlAYWEhhw8fxnEcmpqaKCoqYtKkSWRnZzNz5kza29tv6IsWEbkZXPMV8L333su9997LypUrmTFjxnUfvKKigieffJLe3l4Azp07R2pqKh7P4LJ+v59QKARAKBTi9ttvHwzl8ZCSksK5c+cIhULMmzcvdkyfzxebIyIynl2zgIf09fWxefNmPv74YyKRSGz8hz/84efOef3110lPT2fu3Ln84he/uPGk18G2LbzeKaOYlzCqeWNJGZRhiGWB7UnAAjweG9uTQHLyZBzH3fU9HhsLjK4/xM31hzPWz4kRFfBf/uVf8vWvf52ysjISEkZ25tovf/lLmpubaWlp4dKlS/T09LBz5066u7uJRCJ4PB6CwSA+nw8YfGV75swZ/H4/kUiE8+fPc9ttt+Hz+QgGg7HjhkKh2JzPE406dHZeGFHOy3m9U0Y1bywpgzIMSUy0iUYGcIBIJEo0MkBPzyX6+0f2/stYrR+JRPF4bKPrD3Fz/eGM9jmRmZky7PiI2tTj8fDII49wzz33MHfu3Niva3n88cdpaWmhubmZ559/noULF/K9732PBQsWsH//fgBqa2vJz88HID8/n9raWgD279/PwoULsSyL/Px8Ghoa6Ovr49SpU5w4cYJ77rlnxF+4iMjNakQFvGTJEl5++WXC4TCdnZ2xX6Px5JNP8tJLLxEIBOjs7KSsrAyA0tJSOjs7CQQCvPTSSzzxxBMA3Hnnndx///088MADfOtb32LLli06A0JEJoQRbUEMvTL953/+59iYZVmxMxh+lwULFrBgwQIAsrOzqampuepzJk+e/LlnVqxZs4Y1a9aMaC0RkfFiRAXc3Nwc7xwiIrecERVwXV3dsOMlJSVjGkZE5FYyogL+z//8z9jjS5cucfjwYebMmaMCFhG5ASMq4M2bN1/xcXd3N4899lhcAomI3CpGdTvKpKSkK26WIyIi129Er4D//M//PPZ4YGCA//7v/+b++++PWygRkVvBiAr4m9/8ZuyxbdvMmDEDv98ft1AiIreCEW1B3HvvvcyaNYve3l66u7tJTEyMdy4RkQlvRAX885//nLKyMl599VX+/d//PfZYRERGb0RbEP/4j/9ITU0NGRkZAHzyySesWrWKZcuWxTWciMhENqJXwI7jxMoXwOv14pi8J5yIyAQwolfAeXl5PProoxQVFQGDWxKLFi2KazARkYnumgV88uRJzp49y1/91V/R2NgY+0nI8+fP58EHH3QloIjIRHXNLYiKigqSk5MBKCgoYNOmTWzatIlAIEBFRYUrAUVEJqprFvDZs2f50pe+dNX4l770JT7++OO4hRIRuRVcs4DPnz//ub/36aefjnkYEZFbyTULeO7cuezZs+eq8b179zJnzpy4hRIRuRVc8024p59+mr/4i7/g3/7t32KF+95779Hf309VVZUrAUVEJqprFvC0adP40Y9+xFtvvcVvfvMbABYvXkxOTo4r4UREJrIRnQe8cOFCFi5cGO8sIiK3lFHdD1hERG6cClhExBAVsIiIISpgERFDVMAiIoaogEVEDFEBi4gYogIWETFEBSwiYogKWETEEBWwiIghKmAREUPiVsCXLl2itLSUBx98kKKiIr7//e8DcOrUKcrKyggEAmzYsIG+vj4A+vr62LBhA4FAgLKyMk6fPh071gsvvEAgEKCwsJDW1tZ4RRYRcVXcCnjSpEns3r2bn/70p9TV1dHa2srRo0fZtWsXq1at4rXXXiM1NZWamhpg8CbvqampvPbaa6xatYpdu3YB8OGHH9LQ0EBDQwMvvvgif/3Xf000Go1XbBER18StgC3LYurUqQBEIhEikQiWZfHWW29RWFgIwMqVK2lqagKgubmZlStXAlBYWMjhw4dxHIempiaKioqYNGkS2dnZzJw5k/b29njFFhFxzYjuBzxa0WiUhx56iI8++ohHHnmE7OxsUlNT8XgGl/X7/YRCIQBCoRC33377YCiPh5SUFM6dO0coFGLevHmxY/p8vticz2PbFl7vlOvOa9sJo5o3lpRBGYZYFtieBCzA47GxPQkkJ0/Gcdxd3+OxscDo+kPcXH84Y/2ciGsB27ZNfX093d3drFu3juPHj8dzuZho1KGz88J1z/N6p4xq3lhSBmUYkphoE40M4ACRSJRoZICenkv097uzBTe0fiQSxeOxja4/xM31hzPa50RmZsqw466cBZGamsqCBQs4evQo3d3dRCIRAILBID6fDxh8ZXvmzBlgcMvi/Pnz3Hbbbfh8PoLBYOxYoVAoNkdEZDyLWwF/8skndHd3A4M/wv7QoUPMnj2bBQsWsH//fgBqa2vJz88HID8/n9raWgD279/PwoULsSyL/Px8Ghoa6Ovr49SpU5w4cYJ77rknXrFFRFwTty2IcDjMU089RTQaxXEcli1bxpIlS7jjjjt47LHHqKys5O6776asrAyA0tJSnnzySQKBAGlpafzd3/0dAHfeeSf3338/DzzwALZts2XLFmzbvtbSIiLjQtwK+Pd+7/eoq6u7ajw7Ozt26tnlJk+eHDtX+LetWbOGNWvWjHlGkWuxrMF9yMuZ3H+UiSeub8KJjFeJiTb/962POB4+HxubOW0qpffcrhKWMaMCFvkcJz/p5diZbtMxZALTvSBERAxRAYuIGKICFhExRAUsImKIClhExBAVsIiIISpgERFDVMAiIoaogEVEDFEBi4gYogIWETFEBSwiYogKWETEEBWwiIghKmAREUNUwCIihqiARUQMUQGLiBiiAhYRMUQFLCJiiApYRMQQFbCIiCEqYBERQ1TAIiKGqIBFRAxRAYuIGKICFhExRAUsImKIClhExJC4FfCZM2f4kz/5Ex544AGKiorYvXs3AJ2dnZSXl1NQUEB5eTldXV0AOI7Djh07CAQCFBcX8/7778eOVVtbS0FBAQUFBdTW1sYrsoiIq+JWwLZt89RTT/Hzn/+cH//4x/zrv/4rH374IdXV1eTk5NDY2EhOTg7V1dUAtLS0cOLECRobG9m+fTvbtm0DBgu7qqqKPXv2sHfvXqqqqmKlLSIynsWtgLOyspgzZw4AycnJzJo1i1AoRFNTEyUlJQCUlJRw4MABgNi4ZVnMnz+f7u5uwuEwbW1t5Obm4vV6SUtLIzc3l9bW1njFFhFxjceNRU6fPs2vfvUr5s2bR0dHB1lZWQBkZmbS0dEBQCgUwu/3x+b4/X5CodBV4z6fj1AodM31bNvC651y3TltO2FU88aSMtwcGSxr8L8ejx0bsz0JJCdPxnHcy2B7ErA+y2FqfY/HxsLc13/598DN9Ycz1s/LuBdwb28v69ev5+mnnyY5OfmK37MsC2vomT6GolGHzs4L1z3P650yqnljSRlujgyJiYN/6SORaGwsGhmgp+cS/f3Rz5s25hmikQGcz3KYWj8SieLx2EbXH+Lm+sMZ7fMyMzNl2PG4ngXR39/P+vXrKS4upqCgAICMjAzC4TAA4XCY9PR0YPCVbTAYjM0NBoP4fL6rxkOhED6fL56xRURcEbcCdhyHZ555hlmzZlFeXh4bz8/Pp66uDoC6ujqWLl16xbjjOBw9epSUlBSysrLIy8ujra2Nrq4uurq6aGtrIy8vL16xRURcE7ctiHfffZf6+nruuusuVqxYAcDGjRtZvXo1GzZsoKamhunTp1NZWQnA4sWLOXjwIIFAgKSkJCoqKgDwer2sXbuW0tJSANatW4fX641XbBER18StgP/wD/+QX//618P+3tA5wZezLIutW7cO+/mlpaWxAhYRmSh0JZyIiCEqYBERQ1TAIiKGqIBFRAxRAYuIGKICFhExRAUsImKIKzfjEREZj4buCRIvKmARkWEkJtrUtJ/h5NleAGZOm8qq+/7PmK6hAhYR+Rwnz/Zy7Ex33I6vPWAREUNUwCIihqiARUQMUQGLiBiiAhYRMUQFLCJiiApYRMQQFbCIiCEqYBERQ1TAIiKGqIBFRAxRAYuIGKICFhExRAUsImKIClhExBAVsIiIISpgERFDVMAiIoaogEVEDFEBi4gYogIWETEkbgW8adMmcnJyWL58eWyss7OT8vJyCgoKKC8vp6urCwDHcdixYweBQIDi4mLef//92Jza2loKCgooKCigtrY2XnFFRFwXtwJ+6KGHePHFF68Yq66uJicnh8bGRnJycqiurgagpaWFEydO0NjYyPbt29m2bRswWNhVVVXs2bOHvXv3UlVVFSttEZHxLm4F/JWvfIW0tLQrxpqamigpKQGgpKSEAwcOXDFuWRbz58+nu7ubcDhMW1sbubm5eL1e0tLSyM3NpbW1NV6RRURc5XFzsY6ODrKysgDIzMyko6MDgFAohN/vj32e3+8nFApdNe7z+QiFQr9zHdu28HqnXHc+204Y1byxpAw3RwbLGvyvx2PHxmxPAsnJk3Ec9zLYngSsz3KYWt/jsbEw9/Vf/j0wub7tSSAhYWyfl64W8OUsy8IaepaPsWjUobPzwnXP83qnjGreWFKGmyNDYuLgX7pIJBobi0YG6Om5RH9/9POmjXmGaGQA57McptaPRKJ4PLbR9YeYXD8aGWBgYGBUz8vMzJRhx109CyIjI4NwOAxAOBwmPT0dGHxlGwwGY58XDAbx+XxXjYdCIXw+n5uRRUTixtUCzs/Pp66uDoC6ujqWLl16xbjjOBw9epSUlBSysrLIy8ujra2Nrq4uurq6aGtrIy8vz83IIiJxE7ctiI0bN/L2229z7tw5Fi1axLe//W1Wr17Nhg0bqKmpYfr06VRWVgKwePFiDh48SCAQICkpiYqKCgC8Xi9r166ltLQUgHXr1uH1euMVWUTEVXEr4Oeff37Y8d27d181ZlkWW7duHfbzS0tLYwUsIjKR6Eo4ERFDVMAiIoaogEVEDFEBi4gYYuxCDJHfNnTxA/zvlWgiE5kKWG4KiYk2Ne1nOHm2F4BZWSmsnOtz7aonERNUwHLTOHm2l2NnuoHB6+5FJjo9y0VEDFEBi4gYogIWETFEBSwiYogKWETEEBWwiIghKmAREUNUwCIihqiARUQMUQGLiBiiAhYRMUQFLCJiiApYRMQQFbCIiCEqYBERQ1TAIiKGqIBFRAxRAYuIGKICFhExRAUsImKIClhExBAVsMQkJtokJtpY1uBjEYkv/Vh6AQYLt6b9DCfP9mJ7EviiN4nSe26nvz9qOprIhKUClpiTZ3s5dqYbj8cmGhkwHUdkwtMWhIiIIeOmgFtaWigsLCQQCFBdXW06jojIDRsXBRyNRnn22Wd58cUXaWho4Gc/+xkffvih6Vhj7vI3wPQmmMjENy72gNvb25k5cybZ2dkAFBUV0dTUxB133DGm65h899+2E/jFqU46evqIDjhkpU5mQbaXaNSdvVjbTmDmtKmDjz97E8623fv3+fL1AWamT3V1/WHzpE+9Yi985jR3Mw39mdieBKKRAWPrw635nLhq/csejxXLcRxnzI86xl599VVaW1vZuXMnAHV1dbS3t7NlyxbDyURERm9cbEGIiExE46KAfT4fwWAw9nEoFMLn8xlMJCJy48ZFAX/5y1/mxIkTnDp1ir6+PhoaGsjPzzcdS0TkhoyLN+E8Hg9btmzhW9/6FtFolK997WvceeedpmOJiNyQcfEmnIjIRDQutiBERCYiFbCIiCHjYg843lpaWti5cycDAwOUlZWxevVq1zNs2rSJN954g4yMDH72s5+5vj7AmTNn+M53vkNHRweWZfFHf/RH/Omf/qmrGS5dusQ3vvEN+vr6iEajFBYWsn79elczDBl6v8Hn8/HCCy+4vn5+fj5Tp04lISEB27bZt2+f6xm6u7v57ne/ywcffIBlWVRUVPD7v//7rmY4fvw4jz32WOzjU6dOsX79elatWuVqjh/84Afs3bsXy7K46667eO6555g8efKNHdS5xUUiEWfp0qXORx995Fy6dMkpLi52fvOb37ie4+2333bee+89p6ioyPW1h4RCIee9995zHMdxzp8/7xQUFLj+ZzEwMOD09PQ4juM4fX19TmlpqXPkyBFXMwz5l3/5F2fjxo3O6tWrjay/ZMkSp6Ojw8jaQ77zne84e/bscRzHcS5duuR0dXUZzROJRJz77rvPOX36tKvrBoNBZ8mSJc7Fixcdx3Gc9evXOz/5yU9u+Li3/BbE5Zc5T5o0KXaZs9u+8pWvkJaW5vq6l8vKymLOnDkAJCcnM2vWLEKhkKsZLMti6tTBSz4jkQiRSATLslzNABAMBnnjjTcoLS11fe2bxfnz53nnnXdifwaTJk0iNTXVaKbDhw+TnZ3NjBkzXF87Go3y6aefEolE+PTTT8nKyrrhY97yBRwKhfD7/bGPfT6f66VzMzp9+jS/+tWvmDdvnutrR6NRVqxYwX333cd9991nJENFRQVPPvkkCQlm/4o8+uijPPTQQ/z4xz92fe3Tp0+Tnp7Opk2bKCkp4ZlnnuHChQuu57hcQ0MDy5cvd31dn8/HN7/5TZYsWUJeXh7Jycnk5eXd8HFv+QKWq/X29rJ+/XqefvppkpOTXV/ftm3q6+s5ePAg7e3tfPDBB66u//rrr5Oens7cuXNdXfe3vfLKK9TW1vJP//RPvPzyy7zzzjuurh+JRDh27Bh//Md/TF1dHUlJSUZvBdvX10dzc68aDOAAAAOCSURBVDPLli1zfe2uri6amppoamqitbWVixcvUl9ff8PHveULWJc5X6m/v5/169dTXFxMQUGB0SypqaksWLCA1tZWV9f95S9/SXNzM/n5+WzcuJG33nqLJ554wtUMQOx5mJGRQSAQoL293dX1/X4/fr8/9n8gy5Yt49ixY65muFxLSwtz5sxh2rRprq996NAhvvjFL5Kenk5iYiIFBQUcOXLkho97yxewLnP+X47j8MwzzzBr1izKy8uNZPjkk0/o7u4G4NNPP+XQoUPMmjXL1QyPP/44LS0tNDc38/zzz7Nw4UJ27drlaoYLFy7Q09MTe/zmm2+6fvVnZmYmfr+f48ePA4P7r7Nnz3Y1w+UaGhooKioysvb06dP5j//4Dy5evIjjOGP2Z3HLn4Z2s1zmvHHjRt5++23OnTvHokWL+Pa3v01ZWZmrGd59913q6+u56667WLFiRSzX4sWLXcsQDod56qmniEajOI7DsmXLWLJkiWvr3yw6OjpYt24dMLgnvnz5chYtWuR6js2bN/PEE0/Q399PdnY2zz33nOsZYPAfoUOHDvHss88aWX/evHkUFhaycuVKPB4Pd999Nw8//PANH1eXIouIGHLLb0GIiJiiAhYRMUQFLCJiiApYRMQQFbCIiCG3/Glocuu6++67ueuuu4hEIti2TUlJCatWrTJ++bHcOlTAcsv6whe+ELuctKOjg8cff5yenh5jt7+UW4/+qRdh8HLf7du38/LLL+M4DtFolL/927/la1/7GsXFxfzoRz+KfW51dTXFxcU8+OCDrl8hJxOLXgGLfCY7O5toNEpHRwdNTU2kpKTwk5/8hL6+Pr7+9a+Tm5vL8ePHaW5uZs+ePSQlJdHZ2Wk6toxjKmCRYbz55pv8+te/Zv/+/cDgvXFPnjzJ4cOHeeihh0hKSgLA6/WajCnjnApY5DOnTp3Ctm0yMjJwHIfvfve7fPWrX73ic9ra2gylk4lIe8AiDN6FbevWrXzjG9/Asizy8vJ45ZVX6O/vB+B//ud/uHDhAvfddx/79u3j4sWLANqCkBuim/HILeu3T0NbsWIF5eXlJCQkMDAwQGVlJa+//jqO43Dbbbfx93//96SkpFBdXU1dXR2JiYksXryYjRs3mv5SZJxSAYuIGKItCBERQ1TAIiKGqIBFRAxRAYuIGKICFhExRAUsImKIClhExJD/D3llE5IGD9ynAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDJThMbYD-Co"
      },
      "source": [
        "Description of lengths of normalized texts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grRvom9SGbg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f37efd5-e75e-487a-b394-231cccbd58d7"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "STOP_SET = set(stopwords.words('english'))    \n",
        "REPLACE_BY_SPACE = re.compile(r'[/(){}\\[\\]\\|@.,;]')\n",
        "GOOD_SYMBOLS = re.compile(r'[^0-9a-z !?]')\n",
        "PUNCT_SPACE = re.compile(r'([!?])')\n",
        "EXTRA_SPACE = re.compile(r'\\s+')\n",
        "\n",
        "def text_prepare(s):\n",
        "    s = s.lower()\n",
        "    s = REPLACE_BY_SPACE.sub(' ', s)\n",
        "    s = GOOD_SYMBOLS.sub('', s)\n",
        "    s = ' '.join([w for w in s.split() \n",
        "                    if w and w not in STOP_SET])\n",
        "    s = PUNCT_SPACE.sub(r' \\1 ', s)\n",
        "    s = EXTRA_SPACE.sub(' ', s)\n",
        "    return s.strip()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8KQQTtEOT2u"
      },
      "source": [
        "df['Prep'] = [text_prepare(s) for s in df['Atext']]\n",
        "df['Len'] = [len(s.split()) for s in df['Prep']]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fh3QeGnfIQP"
      },
      "source": [
        "Text lengths (max, mean, std) and S/W ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viHi53PFc6zx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b73d3f58-9f75-43e0-ca89-fed2bdba1bc4"
      },
      "source": [
        "print('Prepared text lengths:\\n\\tmax = %d\\n\\tmean = %.2f\\n\\tstd = %.2f' %\n",
        "      (df['Len'].max(), df['Len'].mean(), df['Len'].std()))\n",
        "print('\\n(# of samples / # of words per sample): %.2f' % \n",
        "      (len(df) / df['Len'].mean()))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prepared text lengths:\n",
            "\tmax = 77\n",
            "\tmean = 31.62\n",
            "\tstd = 15.34\n",
            "\n",
            "(# of samples / # of words per sample): 742.77\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjlmwaVPe599"
      },
      "source": [
        "The age group doesn't seem to correlate with the text length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-LkltBcNruc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "0327a60b-f863-4d32-b8b5-a578b17b072f"
      },
      "source": [
        "sns.lineplot(data=df, x='Dec', y='Len')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc38ade64a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN1mZyiaaqfh"
      },
      "source": [
        "## 2. Data splits\n",
        "Train 70% - Val 15% - Test 15% (16k, 3.5k, 3.5k)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6oz9l7Aheg9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a464c0-a9c4-442a-b4bc-c8b1fef79c63"
      },
      "source": [
        "## get the test set indices and the rest\n",
        "source_col = 'Prep'\n",
        "target_col = 'Dec'\n",
        "random_state = 1\n",
        "idx_, idx_test = next(SSSplit(n_splits=1, \n",
        "                      test_size=0.15, \n",
        "                      random_state=random_state).split(df[source_col], \n",
        "                                                       df[target_col]))\n",
        "X_test, y_test = df[source_col][idx_test], df[target_col][idx_test]\n",
        "\n",
        "## get the (train + val) sets\n",
        "X_train_val, y_train_val = df[source_col][idx_], df[target_col][idx_]\n",
        "num_classes = len(set(y_train_val))\n",
        "print('Class label set:', set(y_train_val))\n",
        "\n",
        "idx_train, idx_val = next(\n",
        "    SSSplit(n_splits=1, \n",
        "            test_size=15 / 85, \n",
        "            random_state=random_state).split(X_train_val, \n",
        "                                             y_train_val))\n",
        "X_train, y_train = df[source_col][idx_train], df[target_col][idx_train]\n",
        "X_val, y_val = df[source_col][idx_val], df[target_col][idx_val]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class label set: {0, 1, 2, 3, 4, 5, 6, 7, 8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ_Jy65_VLTS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11fc6da0-3eee-4825-8357-da25dd149288"
      },
      "source": [
        "for i in range(5):\n",
        "    print('\"%s...\"' % X_train.iloc[i][:50], y_train.iloc[i])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"great classic boyfriend jean distressed bought sto...\" 7\n",
            "\"unique love unique tshirt fall colors ranchers the...\" 5\n",
            "\"best shirt ever bought colors wish could buy color...\" 7\n",
            "\"dont miss top great top worth money nice flow soft...\" 5\n",
            "\"cute romper material meh cute romper love pattern ...\" 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4GQhWF1AQ1m"
      },
      "source": [
        "## 3. Baseline\n",
        "Since S/W ratio is less than 1500 (see [this recommendation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5?hl=en)), it makes sense to try n-gram bag-of-words models. These baseline models give a sense about at least how much better we can do than guessing randomly or by the mode (70s)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkCJtcwE_Fc1"
      },
      "source": [
        "def guessMode(input, mode=6):\n",
        "    return np.array([mode] * input.shape[0])\n",
        "\n",
        "def guessRandom(input, lo=0, hi=8):\n",
        "    return np.random.randint(lo, hi + 1, input.shape[0])\n",
        "\n",
        "def model_assess(title, y_true, y_pred):\n",
        "    print('%s:\\n' % title,\n",
        "        'MAE: %.3f' % MAE(y_true, y_pred),\n",
        "        'Acc: %.3f' % accuracy_score(y_true, y_pred),\n",
        "        'F1: %.3f' % f1_score(y_true, y_pred, average='micro'), \n",
        "        end='\\n\\n')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT59pkph_vvK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fdef517-551e-4e10-a07b-d3b0ac19eb38"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(min_df=5, max_df=0.9, \n",
        "                                   ngram_range=(1, 2),\n",
        "                                   token_pattern='(\\S+)')\n",
        "\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf =  tfidf_vectorizer.transform(X_val)\n",
        "X_test_tfidf =  tfidf_vectorizer.transform(X_test)\n",
        "print('TFIDF vocab size', len(tfidf_vectorizer.vocabulary_))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TFIDF vocab size 19696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyqXJq_n0jbD"
      },
      "source": [
        "It is reported [here](https://rikunert.com/ordinal_rating) that ordinal classification (e.g. ratings) are better served by *ordered logistic regression* (LAT) than by *logistic regressions* (LR).  \n",
        "* features of 90s are closer to features of 80s than those of 50s;\n",
        "* predicting 90s for 80s is better than predicting 50s.\n",
        "\n",
        "Both LAT & LR are experiemnted.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIEQE-_WBx5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06bb0180-f373-4583-e11f-0c0a52de01b2"
      },
      "source": [
        "clf_LR = LogisticRegression(C=1, max_iter=1000)\n",
        "clf_LAT = LogisticAT(alpha=0.01, verbose=1, max_iter=10000)\n",
        "clf_LR.fit(X_train_tfidf, y_train)\n",
        "clf_LAT.fit(X_train_tfidf, y_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticAT(alpha=0.01, max_iter=10000, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD7br4LbQ1W7"
      },
      "source": [
        "n-grams models fare slightly better than guessing, but underfit even when minimizing regularization coef. \n",
        "For this particular task, it seems that ignoring the ordinal nature of the labels doesn't hurt much. **Thus the following deep models go with multiclass classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAVVxe8ZI2Wn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec4ac6a0-d0a0-4b9c-e1ef-a625a284d1b1"
      },
      "source": [
        "model_assess('OrdLogiAT - train', \n",
        "             y_train, clf_LAT.predict(X_train_tfidf))\n",
        "model_assess('OrdLogiAT - val', \n",
        "             y_val, clf_LAT.predict(X_val_tfidf))\n",
        "model_assess('LogiReg - train', \n",
        "             y_train, clf_LR.predict(X_train_tfidf))\n",
        "model_assess('LogiReg - val', \n",
        "             y_val, clf_LR.predict(X_val_tfidf))\n",
        "model_assess('Guess mode - val', \n",
        "             y_val, guessMode(X_val_tfidf))\n",
        "model_assess('Guess random - val', \n",
        "             y_val, guessRandom(X_val_tfidf))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrdLogiAT - train:\n",
            " MAE: 0.111 Acc: 0.895 F1: 0.895\n",
            "\n",
            "OrdLogiAT - val:\n",
            " MAE: 1.331 Acc: 0.236 F1: 0.236\n",
            "\n",
            "LogiReg - train:\n",
            " MAE: 0.577 Acc: 0.660 F1: 0.660\n",
            "\n",
            "LogiReg - val:\n",
            " MAE: 0.991 Acc: 0.343 F1: 0.343\n",
            "\n",
            "Guess mode - val:\n",
            " MAE: 0.984 Acc: 0.306 F1: 0.306\n",
            "\n",
            "Guess random - val:\n",
            " MAE: 2.764 Acc: 0.104 F1: 0.104\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs_Xb-9i5qY8"
      },
      "source": [
        "## 4. Deep models\n",
        "Since the baseline capacity is insufficient, we experiment with deep models:\n",
        "*   Basic CNN (with frozen GloVe embedding)\n",
        "*   Separable CNN\n",
        "*   Transformer\n",
        "\n",
        "These are parallizable & computationally efficient.  \n",
        "The next step can be character-level CNN, large-scale pretrained encoder (BERT), recurrent networks ...\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV0WQHn2A2Ym"
      },
      "source": [
        "#### build vocabulary & tokenzier\n",
        "MAX_LEN = 60                # roughly (mean + 2 * std)\n",
        "MAX_VOCAB_SIZE = 2 ** 14    # comparable to TFIDF vocab size\n",
        "\n",
        "tokenizer = prep.text.Tokenizer(\n",
        "    num_words=MAX_VOCAB_SIZE,\n",
        "    filters='\"#$%&()*+.,-/:;<=>@[\\\\]^_`{|}~\\t\\n')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "vocab_size = min(MAX_VOCAB_SIZE, len(tokenizer.word_index) + 1)\n",
        "\n",
        "X_train_vec = tokenizer.texts_to_sequences(X_train)\n",
        "max_len = len(max(X_train_vec, key=len))\n",
        "max_len = min(MAX_LEN, max_len)\n",
        "X_train_vec = prep.sequence.pad_sequences(X_train_vec, maxlen=max_len)\n",
        "\n",
        "X_val_vec = tokenizer.texts_to_sequences(X_val)\n",
        "X_val_vec = prep.sequence.pad_sequences(X_val_vec, maxlen=max_len)\n",
        "\n",
        "X_test_vec = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_vec = prep.sequence.pad_sequences(X_test_vec, maxlen=max_len)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz_d-493OC0X"
      },
      "source": [
        "def get_opt():\n",
        "    return tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=3)]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puJYw8YKR2M-"
      },
      "source": [
        "### 4.1 Basic CNN\n",
        "As described in [here](https://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf) and [here](https://arxiv.org/pdf/1408.5882.pdf) (with frozen GloVe embedding).  \n",
        "GloVe + \"basic\" models won't benifit much from tuable embedding (Sam Bowman p.c.). Experimented and confirmed (results omitted)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z015msscxBhU"
      },
      "source": [
        "SPACY_EMB_SIZE = 300\n",
        "emb_matrix = np.zeros((vocab_size, SPACY_EMB_SIZE))\n",
        "for w, i in tokenizer.word_index.items():\n",
        "    emb_matrix[i] = spacy_nlp(w).vector"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2nR7SoYyUrv"
      },
      "source": [
        "def build_cnn_model(embedding_dim,\n",
        "                    num_classes,\n",
        "                    num_features,\n",
        "                    input_shape,\n",
        "                    filters=100,\n",
        "                    hidden_dim=256,\n",
        "                    dropout_rate=0.2):\n",
        "    t_in = L.Input(shape=input_shape, dtype='int64')\n",
        "    embedding = L.Embedding(\n",
        "        input_dim=num_features,\n",
        "        output_dim=embedding_dim,\n",
        "        embeddings_initializer=initializers.Constant(emb_matrix),\n",
        "        trainable=False)(t_in)\n",
        "    \n",
        "    tri_gram = L.Conv1D(filters, 3, padding='same', \n",
        "                        activation='relu')(embedding)\n",
        "    tri_gram = L.GlobalMaxPooling1D()(tri_gram)\n",
        "    \n",
        "    quart_gram = L.Conv1D(filters, 4, padding='same', \n",
        "                          activation='relu')(embedding)\n",
        "    quart_gram = L.GlobalMaxPooling1D()(quart_gram)\n",
        "    \n",
        "    quint_gram = L.Conv1D(filters, 5, padding='same', \n",
        "                          activation='relu')(embedding)\n",
        "    quint_gram = L.GlobalMaxPooling1D()(quint_gram)\n",
        "\n",
        "    concat = L.Concatenate(axis=1)([tri_gram, quart_gram, quint_gram])\n",
        "    t_den = L.Dense(hidden_dim, activation='relu')(concat)\n",
        "    t_den = L.Dropout(dropout_rate)(t_den)\n",
        "    t_out = L.Dense(num_classes, activation='softmax')(t_den)\n",
        "    model = models.Model(t_in, t_out)\n",
        "    return model\n",
        "\n",
        "model_cnn = build_cnn_model(\n",
        "    embedding_dim=SPACY_EMB_SIZE,\n",
        "    num_classes=num_classes,\n",
        "    num_features=vocab_size,\n",
        "    input_shape=[max_len],\n",
        "    dropout_rate=0.5)\n",
        "\n",
        "model_cnn.compile(optimizer=get_opt(),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['acc'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOC4XqeLRise",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec3dec76-9739-4094-b49f-486abdc1ff64"
      },
      "source": [
        "model_cnn.fit(\n",
        "    X_train_vec,\n",
        "    y_train,                     \n",
        "    epochs=40,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=(X_val_vec, y_val), \n",
        "    verbose=1, # progress bar  \n",
        "    batch_size=128)\n",
        "print('Trainning stopped.')\n",
        "model_cnn.save(os.path.join(home_path, 'text2dec_cnn_model.h5'))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "129/129 [==============================] - 2s 14ms/step - loss: 1.7099 - acc: 0.2891 - val_loss: 1.6359 - val_acc: 0.3063\n",
            "Epoch 2/40\n",
            "129/129 [==============================] - 1s 11ms/step - loss: 1.6078 - acc: 0.3200 - val_loss: 1.6114 - val_acc: 0.3185\n",
            "Epoch 3/40\n",
            "129/129 [==============================] - 1s 11ms/step - loss: 1.5486 - acc: 0.3462 - val_loss: 1.5977 - val_acc: 0.3222\n",
            "Epoch 4/40\n",
            "129/129 [==============================] - 1s 11ms/step - loss: 1.4538 - acc: 0.3936 - val_loss: 1.6023 - val_acc: 0.3216\n",
            "Epoch 5/40\n",
            "129/129 [==============================] - 1s 11ms/step - loss: 1.3229 - acc: 0.4648 - val_loss: 1.6348 - val_acc: 0.3196\n",
            "Epoch 6/40\n",
            "129/129 [==============================] - 1s 10ms/step - loss: 1.1106 - acc: 0.5566 - val_loss: 1.7613 - val_acc: 0.3120\n",
            "Trainning stopped.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahlAoMTmO4rG"
      },
      "source": [
        "### 4.2 sepCNN \n",
        "[Depthwise Separable Convolutional Network](https://arxiv.org/abs/1610.02357), recommended [here](https://developers.google.com/machine-learning/guides/text-classification/step-4), where an implementation is given."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpmfUQZ9K-d2"
      },
      "source": [
        "def build_sepcnn_model(filters,\n",
        "                       kernel_size,\n",
        "                       embedding_dim,\n",
        "                       dropout_rate,\n",
        "                       pool_size,\n",
        "                       input_shape,\n",
        "                       num_classes,\n",
        "                       num_features):\n",
        "    \n",
        "    model = models.Sequential()\n",
        "    model.add(L.Embedding(input_dim=num_features,\n",
        "                          output_dim=embedding_dim,\n",
        "                          input_length=input_shape[0]))\n",
        "\n",
        "    model.add(L.Dropout(rate=dropout_rate))\n",
        "    model.add(L.SeparableConv1D(filters=filters,\n",
        "                                kernel_size=kernel_size,\n",
        "                                activation='relu',\n",
        "                                bias_initializer='random_uniform',\n",
        "                                depthwise_initializer='random_uniform',\n",
        "                                padding='same'))\n",
        "    model.add(L.SeparableConv1D(filters=filters,\n",
        "                                kernel_size=kernel_size,\n",
        "                                activation='relu',\n",
        "                                bias_initializer='random_uniform',\n",
        "                                depthwise_initializer='random_uniform',\n",
        "                                padding='same'))\n",
        "    model.add(L.MaxPooling1D(pool_size=pool_size))\n",
        "    \n",
        "    model.add(L.SeparableConv1D(filters=filters * 2,\n",
        "                               kernel_size=kernel_size,\n",
        "                               activation='relu',\n",
        "                               bias_initializer='random_uniform',\n",
        "                               depthwise_initializer='random_uniform',\n",
        "                               padding='same'))\n",
        "    model.add(L.SeparableConv1D(filters=filters * 2,\n",
        "                                kernel_size=kernel_size,\n",
        "                                activation='relu',\n",
        "                                bias_initializer='random_uniform',\n",
        "                                depthwise_initializer='random_uniform',\n",
        "                                padding='same'))\n",
        "    model.add(L.GlobalAveragePooling1D())\n",
        "\n",
        "    model.add(L.Dropout(rate=dropout_rate))\n",
        "    model.add(L.Dense(num_classes, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "model_sepcnn = build_sepcnn_model(\n",
        "    filters=64,\n",
        "    embedding_dim=256,\n",
        "    kernel_size=3,\n",
        "    pool_size=3,\n",
        "    dropout_rate=0.2,\n",
        "    input_shape=[max_len],\n",
        "    num_classes=num_classes,\n",
        "    num_features=vocab_size)\n",
        "\n",
        "model_sepcnn.compile(optimizer=get_opt(),\n",
        "                     loss='sparse_categorical_crossentropy',\n",
        "                     metrics=['acc'])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvVMW_e0XpTE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3443590-0a7a-466b-b4d7-df750eab312c"
      },
      "source": [
        "model_sepcnn.fit(\n",
        "    X_train_vec,\n",
        "    y_train,                            \n",
        "    epochs=40,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=(X_val_vec, y_val), \n",
        "    verbose=1, # progress bar  \n",
        "    batch_size=128)\n",
        "print('Trainning stopped.')\n",
        "model_sepcnn.save(os.path.join(home_path, 'text2dec_sepcnn_model.h5'))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "129/129 [==============================] - 6s 50ms/step - loss: 1.8354 - acc: 0.3020 - val_loss: 1.6401 - val_acc: 0.3060\n",
            "Epoch 2/40\n",
            "129/129 [==============================] - 6s 44ms/step - loss: 1.6287 - acc: 0.3036 - val_loss: 1.6346 - val_acc: 0.3060\n",
            "Epoch 3/40\n",
            "129/129 [==============================] - 6s 43ms/step - loss: 1.6223 - acc: 0.3054 - val_loss: 1.6253 - val_acc: 0.3060\n",
            "Epoch 4/40\n",
            "129/129 [==============================] - 6s 43ms/step - loss: 1.5917 - acc: 0.3113 - val_loss: 1.6169 - val_acc: 0.3066\n",
            "Epoch 5/40\n",
            "129/129 [==============================] - 6s 44ms/step - loss: 1.5312 - acc: 0.3305 - val_loss: 1.6301 - val_acc: 0.2989\n",
            "Epoch 6/40\n",
            "129/129 [==============================] - 5s 43ms/step - loss: 1.4620 - acc: 0.3589 - val_loss: 1.6653 - val_acc: 0.2955\n",
            "Epoch 7/40\n",
            "129/129 [==============================] - 5s 43ms/step - loss: 1.3891 - acc: 0.3863 - val_loss: 1.7800 - val_acc: 0.2830\n",
            "Trainning stopped.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBP0NgAAmDtR"
      },
      "source": [
        "### 4.3 Transformer\n",
        "Implementation found [here](https://keras.io/examples/nlp/text_classification_with_transformer/), with modification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Biujr8zdmRYb"
      },
      "source": [
        "class MultiHeadSelfAttention(L.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads:\n",
        "            raise ValueError('embedding dimension indivisible by # of heads')\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = L.Dense(embed_dim)\n",
        "        self.key_dense = L.Dense(embed_dim)\n",
        "        self.value_dense = L.Dense(embed_dim)\n",
        "        self.combine_heads = L.Dense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, \n",
        "                           self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(inputs)      # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(\n",
        "            query, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        key = self.separate_heads(\n",
        "            key, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(\n",
        "            value, batch_size\n",
        "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(\n",
        "            attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(\n",
        "            attention, (batch_size, -1, self.embed_dim)\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(\n",
        "            concat_attention\n",
        "        )  # (batch_size, seq_len, embed_dim)\n",
        "        return output\n",
        "\n",
        "\n",
        "class TransformerBlock(L.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = models.Sequential(\n",
        "            [L.Dense(ff_dim, activation=\"relu\"), L.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = L.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = L.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = L.Dropout(rate)\n",
        "        self.dropout2 = L.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "\n",
        "class TokenAndPositionEmbedding(L.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.token_emb = L.Embedding(input_dim=vocab_size, \n",
        "                                     output_dim=embed_dim)\n",
        "        self.pos_emb = L.Embedding(input_dim=maxlen, \n",
        "                                   output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions\n",
        "\n",
        "\n",
        "def build_transformer_model(\n",
        "    input_shape,\n",
        "    num_features,\n",
        "    num_classes,\n",
        "    embed_dim,    \n",
        "    num_heads=2,  \n",
        "    ff_dim=32,\n",
        "    hidden_dim=32):\n",
        "\n",
        "    t_in = L.Input(shape=input_shape)\n",
        "    embedding_layer = TokenAndPositionEmbedding(input_shape[0], \n",
        "                                                num_features, \n",
        "                                                embed_dim)\n",
        "    emb = embedding_layer(t_in)\n",
        "    t = TransformerBlock(embed_dim, num_heads, ff_dim)(emb)\n",
        "    t = L.GlobalAveragePooling1D()(t)\n",
        "    t = L.Dropout(0.1)(t)\n",
        "    t = L.Dense(hidden_dim, activation='relu')(t)\n",
        "    t = L.Dropout(0.1)(t)\n",
        "    t_out = L.Dense(num_classes, activation='softmax')(t)\n",
        "\n",
        "    model = models.Model(t_in, t_out)\n",
        "    return model\n",
        "\n",
        "model_transf = build_transformer_model(\n",
        "    input_shape=[max_len],\n",
        "    num_features=vocab_size,\n",
        "    num_classes=num_classes,\n",
        "    embed_dim=128)\n",
        "\n",
        "model_transf.compile(optimizer=get_opt(),\n",
        "                     loss='sparse_categorical_crossentropy',\n",
        "                     metrics=['acc'])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RavMgpodsFtI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b34162d-b386-412a-b409-8bd34b88f9d2"
      },
      "source": [
        "model_transf.fit(\n",
        "    X_train_vec,\n",
        "    y_train ,                            \n",
        "    epochs=40,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=(X_val_vec, y_val),\n",
        "    verbose=1, # progress bar  \n",
        "    batch_size=128)\n",
        "print('Trainning stopped.')\n",
        "model_sepcnn.save(os.path.join(home_path, 'text2dec_transf_model.h5'))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "129/129 [==============================] - 4s 33ms/step - loss: 1.6775 - acc: 0.2896 - val_loss: 1.6111 - val_acc: 0.3225\n",
            "Epoch 2/40\n",
            "129/129 [==============================] - 4s 30ms/step - loss: 1.5536 - acc: 0.3597 - val_loss: 1.5689 - val_acc: 0.3463\n",
            "Epoch 3/40\n",
            "129/129 [==============================] - 4s 31ms/step - loss: 1.3816 - acc: 0.4487 - val_loss: 1.6502 - val_acc: 0.3190\n",
            "Epoch 4/40\n",
            "129/129 [==============================] - 4s 31ms/step - loss: 1.1561 - acc: 0.5505 - val_loss: 1.8611 - val_acc: 0.3162\n",
            "Epoch 5/40\n",
            "129/129 [==============================] - 4s 29ms/step - loss: 0.9123 - acc: 0.6472 - val_loss: 2.1820 - val_acc: 0.3295\n",
            "Trainning stopped.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2aRrvgE_QHe"
      },
      "source": [
        "It turns out that these deep models \n",
        "*   fit the training examples well (actually training loss keeps decreasing if more epochs trained)\n",
        "*   quickly become overfitted (val loss doesn't improve correspondingly)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHNv3vVf-dzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ae99747-80b7-4795-ac45-ad68f980d4fa"
      },
      "source": [
        "model_assess('Basic CNN - val', \n",
        "             y_val, np.argmax(model_cnn.predict(X_val_vec), axis=1))\n",
        "model_assess('SepCNN - val', \n",
        "             y_val, np.argmax(model_sepcnn.predict(X_val_vec), axis=1))\n",
        "model_assess('Transformer - val', \n",
        "             y_val, np.argmax(model_transf.predict(X_val_vec), axis=1))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Basic CNN - val:\n",
            " MAE: 1.076 Acc: 0.312 F1: 0.312\n",
            "\n",
            "SepCNN - val:\n",
            " MAE: 1.115 Acc: 0.283 F1: 0.283\n",
            "\n",
            "Transformer - val:\n",
            " MAE: 1.071 Acc: 0.330 F1: 0.330\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_Uls69DAhBz"
      },
      "source": [
        "## 5. Summary\n",
        "\n",
        "1.  A small dataset. Deep models' overfitting pattern suggests generalization may improve on larger datasets.\n",
        "\n",
        "2. Techniques to scale: character-level CNN ([here](https://arxiv.org/pdf/1509.01626.pdf)), hashing vectorizer \n",
        "\n",
        "3.   If we reduce the number of age groups (3-4 groups), the performance improves on this dataset (val-acc 0.5-0.7). Previous studies on \"age prediction\" usually handle 2-5 classes (e.g. [[1]](https://arxiv.org/pdf/1610.00852.pdf), [[2]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7932459), [[3]](https://www.aclweb.org/anthology/P17-2076.pdf)).\n",
        "\n",
        "4.   Two predictors: contents and styles. But now the domain is limited to clothing review (not able to distinguish ages by topic), and the genre is set as review (there might be spelling clues --- need sub-word encoding to pick up)\n",
        "\n",
        "5.   No clear correlation between age & item type distribution (e.g. tops and dresses are popular for all ages) --- confirmed by experiment: these model perform reasonably well on \"department name\" classification, val-acc > 0.8.\n",
        "\n",
        "\n"
      ]
    }
  ]
}